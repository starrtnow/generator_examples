{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_set = torchvision.datasets.MNIST(root=\"./mnist\", train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_loader = torch.utils.data.DataLoader(dataset=img_set, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_dimension(height, width, kernal, stride, padding, output_padding=(0,0)):\n",
    "    h_out = (height - 1) * stride[0] - 2 * padding[0] + kernal[0] + output_padding[0]\n",
    "    w_out = (width - 1) * stride[1] - 2 * padding[1] + kernal[1] + output_padding[1]\n",
    "    return (h_out, w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dimension(1, 1, (4, 4), (1,1), (0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dimension(4, 4, (4, 4), (2,2), (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dimension(8, 8, (4, 4), (2,2), (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dimension(16, 16, (4, 4), (2,2), (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    #the discriminator\n",
    "    def __init__(self, side, n_hidden, n_chan1, n_chan2, kernal):\n",
    "        super(LeNet, self).__init__()\n",
    "        padding = (kernal - 1)//2\n",
    "        self.conv1 = nn.Conv2d(1, n_chan1, kernal, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(n_chan1, n_chan2, kernal, padding=padding)\n",
    "        \n",
    "        dimension = self.size_after_pool(side, padding, padding)\n",
    "        dimension = self.size_after_pool(dimension, padding, padding)\n",
    "        \n",
    "        self.fc = nn.Linear(dimension * dimension * n_chan2, n_hidden)\n",
    "        self.output = nn.Linear(n_hidden, 1)\n",
    "        \n",
    "        self.drop1 = nn.Dropout2d(p=0.25)\n",
    "        self.drop2 = nn.Dropout2d(p=0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.relu(self.drop1(self.conv1(x)))\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = F.relu(self.drop2(self.conv2(out)))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        out = F.relu(self.fc(out))\n",
    "        out = F.sigmoid(self.output(out))\n",
    "        return out.view(-1, 1)\n",
    "    \n",
    "    def size_after_pool(self, size, stride, sp_ext):\n",
    "        return int((size - sp_ext)/stride) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_batch, n_input, n_z_step):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_input = n_input\n",
    "        self.nzstep = n_z_step\n",
    "        self.n_batch = n_batch\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose2d(n_input, n_z_step * 8, 4, 1, 0, bias=False)\n",
    "        self.conv2 = nn.ConvTranspose2d(n_z_step * 8, n_z_step * 4, 4, 2, 1, bias=False)\n",
    "        self.conv3 = nn.ConvTranspose2d(n_z_step * 4, n_z_step * 2, 4, 2, 1, bias=False)\n",
    "        self.conv4 = nn.ConvTranspose2d(n_z_step * 2, 1, 4, 2, 3, bias=False)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(n_z_step * 8)\n",
    "        self.batch2 = nn.BatchNorm2d(n_z_step * 4)\n",
    "        self.batch3 = nn.BatchNorm2d(n_z_step * 2)\n",
    "    \n",
    "    def generate_noise(self):\n",
    "        noise = torch.FloatTensor(self.n_batch, self.n_input, 1, 1)\n",
    "        noise.normal_()\n",
    "        return noise\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.batch1(self.conv1(x)))\n",
    "        out = F.relu(self.batch2(self.conv2(out)))\n",
    "        out = F.relu(self.batch3(self.conv3(out)))\n",
    "        out = F.tanh(self.conv4(out))\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc = LeNet(28, 500, 16, 32, 5)\n",
    "gen = Generator(100, 512, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerD = torch.optim.Adam(disc.parameters(), lr=2e-4, betas=(0.9, 0.999))\n",
    "optimizerG = torch.optim.Adam(gen.parameters(), lr=2e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss (\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc.cuda()\n",
    "gen.cuda()\n",
    "criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 lossD:  0.17502692341804504  lossG:  3.2645599842071533  took:  104.25778825791035\n",
      "Epoch:  1 lossD:  0.21347205340862274  lossG:  5.313624382019043  took:  103.24735601968246\n",
      "Epoch:  2 lossD:  0.023498620837926865  lossG:  6.631292343139648  took:  103.31037837478203\n",
      "Epoch:  3 lossD:  0.08215543627738953  lossG:  6.47157096862793  took:  103.32489602443883\n",
      "Epoch:  4 lossD:  0.016522588208317757  lossG:  6.773327827453613  took:  103.44342179395716\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c5cc404c9137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mgen_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mgen_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mgen_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mgen_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PYT\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b50205773196>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PYT\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\PYT\\lib\\site-packages\\torch\\nn\\_functions\\thnn\\auto.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, *params)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "one = torch.FloatTensor([1]).cuda()\n",
    "mone = one * -1\n",
    "\n",
    "gen_iter = 0\n",
    "for epoch in range(n_epochs):\n",
    "    current_time = time.clock()\n",
    "    \n",
    "    i = 0 \n",
    "    for image, _ in img_loader:\n",
    "        \n",
    "        disc.zero_grad()\n",
    "        real_image = Variable(image.cuda())\n",
    "        real_label = Variable(torch.ones(100).cuda())\n",
    "        \n",
    "        real_output = disc(real_image)\n",
    "        real_loss = criterion(real_output, real_label)\n",
    "        real_loss.backward()\n",
    "        \n",
    "        #train fake\n",
    "        noise = gen.generate_noise().cuda()\n",
    "        noise = Variable(noise)\n",
    "        \n",
    "        fake_image = gen(noise)\n",
    "        fake_label = Variable(torch.zeros(100).cuda())\n",
    "        \n",
    "        fake_output = disc(fake_image.detach())\n",
    "        fake_loss = criterion(fake_output, fake_label)\n",
    "        fake_loss.backward()\n",
    "        \n",
    "        errD = real_loss + fake_loss\n",
    "        optimizerD.step()\n",
    "        \n",
    "        #GENERATOR\n",
    "        \n",
    "        gen.zero_grad()\n",
    "        gen_label = Variable(torch.ones(100).cuda())\n",
    "        gen_output = disc(fake_image)\n",
    "        gen_loss = criterion(gen_output, gen_label)\n",
    "        gen_loss.backward()\n",
    "        optimizerG.step()\n",
    "        errG = gen_loss\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            torchvision.utils.save_image(fake_image.data, \"fake_image_iep%03d,%03d.png\" % (epoch, i))\n",
    "        \n",
    "        \n",
    "    passed_time = time.clock() - current_time\n",
    "    print(\"Epoch: \", epoch, \"lossD: \", errD.data[0], \" lossG: \", errG.data[0], \" took: \", passed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5      # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.reshape(npimg, (50, 32, 32, 3), order='F')\n",
    "    plt.imshow(npimg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n = Variable(gen.generate_noise().cuda())\n",
    "img = gen(n)\n",
    "torchvision.utils.save_image(img.cpu().data, \"wtf.png\", normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(disc.state_dict(), \"disc.pkl\")\n",
    "torch.save(gen.state_dict(), \"gen.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "imshow(img.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
