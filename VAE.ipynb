{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#dataset = torchvision.datasets.MNIST(root=\"./mnist\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, shuffle=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.reshape(npimg, (50, 32, 32), order='F')\n",
    "    plt.imshow(npimg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, height, width, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.z_dim = z_dim\n",
    "        self.lin1 = nn.Linear(width * height * 3, 400)\n",
    "        \n",
    "        self.mu_out = nn.Sequential(\n",
    "            nn.Linear(400, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, z_dim))\n",
    "        self.var_out = nn.Sequential(\n",
    "            nn.Linear(400, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, z_dim))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.width * self.height * 3)\n",
    "        out = F.relu(self.lin1(X))\n",
    "        mu = self.mu_out(out)\n",
    "        var = self.var_out(out)\n",
    "        return mu, var\n",
    "    \n",
    "    def sample(self, batch_size, mu, log_var):\n",
    "        eps = Variable(torch.randn(batch_size, self.z_dim)).cuda()\n",
    "        return mu + torch.exp(log_var / 2) * eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, width, height, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.lin1 = nn.Sequential(\n",
    "            nn.Linear(z_dim, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 400))\n",
    "        self.out = nn.Linear(400, self.width * self.height * 3)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = F.relu(self.lin1(X))\n",
    "        out = F.sigmoid(self.out(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(32, 32, 300)\n",
    "decoder = Decoder(32, 32, 300)\n",
    "params = list(encoder.parameters()) + list(decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(params, lr=1e-3)\n",
    "recon_loss = nn.BCELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder.cuda()\n",
    "decoder.cuda()\n",
    "recon_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in dataloader:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        X = Variable(img.cuda())\n",
    "\n",
    "        z_mu, z_var = encoder(X)\n",
    "        z = encoder.sample(50, z_mu, z_var).cuda()\n",
    "        X_sample = decoder(z)\n",
    "\n",
    "        rec_loss = recon_loss(X_sample, X)\n",
    "        KL_loss = z_mu.pow(2).add_(z_var.exp()).mul_(-1).add_(1).add_(z_var)\n",
    "        KL_loss = torch.sum(KL_loss).mul_(-0.5)\n",
    "        total_loss = rec_loss + KL_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    fake_images = X_sample.data.view(-1, 3, 32, 32)\n",
    "    torchvision.utils.save_image(fake_images, filename=\"vae%03d.png\" % epoch, normalize=True)\n",
    "    print(\"Epoch: \", epoch, \" total loss: \", total_loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_z = Variable(torch.FloatTensor(50, 300).normal_()).cuda()\n",
    "result = decoder(test_z).data.view(-1, 3, 32, 32)\n",
    "torchvision.utils.save_image(result, \"vae-results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
